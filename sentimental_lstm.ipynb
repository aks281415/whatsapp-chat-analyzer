{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vMwY_NDrVc9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1340537a-61c4-4ab9-ebcd-79d4cdb86bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Dependencies Installed !\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import Callback\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense,Embedding,LSTM\n",
        "\n",
        "print(\"All Dependencies Installed !\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VueQJ6Xwdhm3",
        "outputId": "24f19390-2e1b-42f1-e270-36d7e69a703a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/IMDB Dataset.csv\")\n",
        "df[\"sentiment\"].replace({\"positive\": 1, \"negative\": 0}, inplace=True)\n",
        "\n",
        "x = np.array(df[\"review\"].values)\n",
        "y = np.array(df[\"sentiment\"].values)\n",
        "\n",
        "x_filtered = []\n",
        "\n",
        "for review in x:\n",
        "\n",
        "    #lowercasing the sentence\n",
        "    review = review.lower()\n",
        "\n",
        "    # removing punctuations from sentence\n",
        "    for i in review:\n",
        "        punc = '''  !()-[]{};:'\"\\,<>./?@#$%^&*_~  '''\n",
        "        if i in punc :\n",
        "            review = review.replace(i, \" \")\n",
        "\n",
        "    x_filtered.append(review)\n",
        "\n",
        "print(\"Data Preparation Stage-1 completed !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUVRpu0DafXK",
        "outputId": "7e13a3f5-a6de-4a5f-8896-d4d174a884ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Preparation Stage-1 completed !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_filtered[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anNZmoh_kApV",
        "outputId": "e2301034-f527-4161-db85-96d907094b24"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one of the other reviewers has mentioned that after watching just 1 oz episode you ll be hooked  they are right  as this is exactly what happened with me  br    br   the first thing that struck me about oz was its brutality and unflinching scenes of violence  which set in right from the word go  trust me  this is not a show for the faint hearted or timid  this show pulls no punches with regards to drugs  sex or violence  its is hardcore  in the classic use of the word  br    br   it is called oz as that is the nickname given to the oswald maximum security state penitentary  it focuses mainly on emerald city  an experimental section of the prison where all the cells have glass fronts and face inwards  so privacy is not high on the agenda  em city is home to many  aryans  muslims  gangstas  latinos  christians  italians  irish and more    so scuffles  death stares  dodgy dealings and shady agreements are never far away  br    br   i would say the main appeal of the show is due to the fact that it goes where other shows wouldn t dare  forget pretty pictures painted for mainstream audiences  forget charm  forget romance   oz doesn t mess around  the first episode i ever saw struck me as so nasty it was surreal  i couldn t say i was ready for it  but as i watched more  i developed a taste for oz  and got accustomed to the high levels of graphic violence  not just violence  but injustice  crooked guards who ll be sold out for a nickel  inmates who ll kill on order and get away with it  well mannered  middle class inmates being turned into prison bitches due to their lack of street skills or prison experience  watching oz  you may become comfortable with what is uncomfortable viewing    thats if you can get in touch with your darker side \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding each sentence\n",
        "vocalbulary_size = 5000\n",
        "onehot_encoded = [one_hot(review,vocalbulary_size) for review in x_filtered]\n",
        "\n",
        "# Padding each encoded sentence to have a max_length=500\n",
        "max_length=500\n",
        "x_padded = pad_sequences(onehot_encoded,max_length,padding=\"post\")\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(x_padded,y,test_size=0.2)\n",
        "\n",
        "print(\"Data Preparation Stage-2 completed !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esGFdZUNbksJ",
        "outputId": "6b763b8d-5ff3-4180-9c76-28927c7005ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Preparation Stage-2 completed !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "embeded_vector_size = 35\n",
        "model.add(Embedding(vocalbulary_size,embeded_vector_size,input_length=max_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=[\"accuracy\"])\n",
        "\n",
        "print(model.summary())\n",
        "print(\"Model Creation Completed !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ygyhgl0yb5BP",
        "outputId": "9ddc5e90-a7de-49c8-a762-8f9e15565f7f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 35)           175000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               54400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 229501 (896.49 KB)\n",
            "Trainable params: 229501 (896.49 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model Creation Completed !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Keras callback to stop training when certain accuracy is achieved.\n",
        "class MyThresholdCallback(Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(MyThresholdCallback, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_acc = logs[\"val_accuracy\"]\n",
        "        if val_acc >= self.threshold:\n",
        "            self.model.stop_training = True\n",
        "            model_name = (\"IMDB_sentiment_analysis_\"+str(val_acc))\n",
        "            model.save(model_name)\n",
        "\n",
        "# Model converges at 0.87 accuracy with current hyperparameters.\n",
        "model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test),callbacks=[MyThresholdCallback(threshold=0.87)])\n",
        "\n",
        "model.save(\"sentiment_analysis\")\n",
        "\n",
        "print(\"Model Training Completed !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcrtBg79b9Gb",
        "outputId": "b2739873-3616-478c-b84f-908d63e200e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1250/1250 [==============================] - 111s 86ms/step - loss: 0.6926 - accuracy: 0.5083 - val_loss: 0.6908 - val_accuracy: 0.5183\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 47s 38ms/step - loss: 0.6713 - accuracy: 0.5556 - val_loss: 0.6075 - val_accuracy: 0.7075\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 35s 28ms/step - loss: 0.6471 - accuracy: 0.5845 - val_loss: 0.6957 - val_accuracy: 0.5251\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 31s 24ms/step - loss: 0.6112 - accuracy: 0.6506 - val_loss: 0.6502 - val_accuracy: 0.6068\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 0.6040 - accuracy: 0.6546 - val_loss: 0.6924 - val_accuracy: 0.5239\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.6167 - accuracy: 0.6166 - val_loss: 0.6233 - val_accuracy: 0.6833\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 0.5955 - accuracy: 0.6606 - val_loss: 0.7047 - val_accuracy: 0.5232\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 0.5923 - accuracy: 0.6661 - val_loss: 0.6527 - val_accuracy: 0.6873\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 31s 25ms/step - loss: 0.5629 - accuracy: 0.7231 - val_loss: 0.6586 - val_accuracy: 0.7056\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.5544 - accuracy: 0.7325 - val_loss: 0.6452 - val_accuracy: 0.7198\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 0.5902 - accuracy: 0.6579 - val_loss: 0.7248 - val_accuracy: 0.5223\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 0.6440 - accuracy: 0.5418 - val_loss: 0.7298 - val_accuracy: 0.5058\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.6428 - accuracy: 0.5484 - val_loss: 0.7212 - val_accuracy: 0.5052\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 0.5521 - accuracy: 0.7173 - val_loss: 0.6113 - val_accuracy: 0.7433\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 27s 21ms/step - loss: 0.4923 - accuracy: 0.7708 - val_loss: 0.5811 - val_accuracy: 0.6811\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 0.4188 - accuracy: 0.8137 - val_loss: 0.4926 - val_accuracy: 0.8121\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 28s 22ms/step - loss: 0.3553 - accuracy: 0.8533 - val_loss: 0.3963 - val_accuracy: 0.8378\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 0.2911 - accuracy: 0.8814 - val_loss: 0.3940 - val_accuracy: 0.8455\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.2480 - accuracy: 0.9014 - val_loss: 0.3530 - val_accuracy: 0.8556\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 27s 22ms/step - loss: 0.2114 - accuracy: 0.9184 - val_loss: 0.3329 - val_accuracy: 0.8694\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 27s 21ms/step - loss: 0.1796 - accuracy: 0.9345 - val_loss: 0.3847 - val_accuracy: 0.8610\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 33s 26ms/step - loss: 0.1542 - accuracy: 0.9456 - val_loss: 0.3790 - val_accuracy: 0.8701\n",
            "Model Training Completed !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''import shutil\n",
        "\n",
        "# Path where your model is saved\n",
        "model_folder_path = '/content/sentiment_analysis'\n",
        "\n",
        "# Create a zip file for the folder to download\n",
        "shutil.make_archive('IMDB_sentiment_analysis', 'zip', model_folder_path)\n",
        "\n",
        "# Download the file\n",
        "from google.colab import files\n",
        "files.download('IMDB_sentiment_analysis.zip')'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5Jb9-ZJ8iHW8",
        "outputId": "2e0beed0-f67f-4e56-88f7-26dd2e7afd8b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fcc67c86-a623-4ebc-8b14-2b2cc5787c91\", \"IMDB_sentiment_analysis.zip\", 2651967)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(sentence: str):\n",
        "    if isinstance(sentence, (str)):\n",
        "        pass\n",
        "    else:\n",
        "        raise Exception(\"Input needs to be of type 'str' \")\n",
        "\n",
        "    # filtering the sentence\n",
        "    sentence = sentence.lower()\n",
        "\n",
        "    punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
        "\n",
        "    for word in sentence:\n",
        "        if word in punc:\n",
        "            sentence = sentence.replace(word, \" \")\n",
        "\n",
        "    # Loading the saved trained model.\n",
        "    from keras.models import load_model\n",
        "\n",
        "    trained_model = load_model(\"/content/IMDB_sentiment_analysis_0.8701000213623047\")\n",
        "\n",
        "    predicted = trained_model.predict(x_test)[2]\n",
        "    sentiment = 1 if predicted > 0.5 else 0\n",
        "\n",
        "    if sentiment == 1:\n",
        "        print(\"Positive\")\n",
        "    else:\n",
        "        print(\"Negative\")\n",
        "\n",
        "    return sentiment\n",
        "\n",
        "\n",
        "get_sentiment(\"That movie was really ok!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiMfQJ8RjG7k",
        "outputId": "b103aa53-ec9a-4a64-9cf3-e2d969a8d4c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 8ms/step\n",
            "Positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}